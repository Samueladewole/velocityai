#!/usr/bin/env python3
"""
Velocity.ai Document Generator Agent
AI-powered compliance document generation with LangChain integration

Features:
- Automated compliance report generation (SOC2, ISO27001, GDPR)
- Evidence-based document creation with real data integration
- Multi-format output (PDF, Word, HTML, Markdown)
- Template-driven document assembly
- Natural language processing for intelligent content generation
- Real-time collaboration and version control
- Regulatory framework-specific formatting
- Executive summary and technical detail generation
"""

import asyncio
import json
import logging
import hashlib
import os
from datetime import datetime, timedelta
from typing import Dict, List, Any, Optional
from dataclasses import dataclass, asdict
from langchain.llms import OpenAI
from langchain.chat_models import ChatOpenAI
from langchain.prompts import PromptTemplate, ChatPromptTemplate
from langchain.chains import LLMChain
from langchain.document_loaders import JSONLoader
from langchain.text_splitter import RecursiveCharacterTextSplitter
from langchain.vectorstores import FAISS
from langchain.embeddings import OpenAIEmbeddings
from langchain.chains.question_answering import load_qa_chain
from langchain.schema import Document
import psycopg2
import psycopg2.extras
from jinja2 import Environment, FileSystemLoader, Template
import markdown
from weasyprint import HTML, CSS
from docx import Document as DocxDocument
from docx.shared import Inches
import pandas as pd
import matplotlib.pyplot as plt
import seaborn as sns
from io import BytesIO
import base64

# Configure logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger('document-generator')

@dataclass
class DocumentRequest:
    """Document generation request"""
    request_id: str
    document_type: str
    framework: str
    output_format: str
    template_id: str
    evidence_filters: Dict[str, Any]
    customizations: Dict[str, Any]
    requester_id: str
    due_date: Optional[str]
    status: str

@dataclass
class GeneratedDocument:
    """Generated document metadata"""
    document_id: str
    request_id: str
    document_type: str
    framework: str
    output_format: str
    file_path: str
    file_size: int
    page_count: int
    evidence_count: int
    generation_time: float
    status: str
    created_at: str
    hash: str

class DocumentGenerator:
    """
    Production Document Generator Agent
    
    Generates compliance documents using AI and evidence data
    with professional formatting and regulatory compliance.
    """
    
    def __init__(self, config: Dict[str, Any]):
        self.config = config
        self.agent_id = config.get('agent_id', 'document-generator-001')
        self.openai_api_key = config.get('openai_api_key')
        self.output_directory = config.get('output_directory', './generated_documents')
        self.template_directory = config.get('template_directory', './document_templates')
        
        # AI components
        self.llm = None
        self.chat_model = None
        self.embeddings = None
        self.vector_store = None
        
        # Template engine
        self.jinja_env = None
        
        # Database connection
        self.db_connection = None
        
        # Request processing
        self.request_queue: List[DocumentRequest] = []
        self.processing_queue: List[DocumentRequest] = []
        self.completed_documents: List[GeneratedDocument] = []
        
        # Performance metrics
        self.metrics = {
            'documents_generated': 0,
            'total_pages_created': 0,
            'evidence_items_processed': 0,
            'generation_time_total': 0.0,
            'requests_completed': 0,
            'requests_failed': 0,
            'last_generation_time': None
        }
        
        # Initialize components
        self._initialize_ai_components()
        self._initialize_templates()
        self._initialize_database()
        self._setup_output_directory()
        
        logger.info(f"üöÄ Document Generator {self.agent_id} initialized")
    
    def _initialize_ai_components(self):
        """Initialize LangChain AI components"""
        try:
            if not self.openai_api_key:
                logger.warning("‚ö†Ô∏è OpenAI API key not provided, using mock responses")
                return
            
            # Initialize OpenAI models
            self.llm = OpenAI(
                openai_api_key=self.openai_api_key,
                temperature=0.1,  # Low temperature for consistent, factual output
                max_tokens=4000
            )
            
            self.chat_model = ChatOpenAI(
                openai_api_key=self.openai_api_key,
                model_name="gpt-4",
                temperature=0.1,
                max_tokens=4000
            )
            
            # Initialize embeddings for evidence retrieval
            self.embeddings = OpenAIEmbeddings(openai_api_key=self.openai_api_key)
            
            logger.info("‚úÖ AI components initialized")
            
        except Exception as e:
            logger.error(f"‚ùå AI component initialization failed: {e}")
            # Continue without AI for basic template processing
    
    def _initialize_templates(self):
        """Initialize Jinja2 template engine"""
        try:
            if not os.path.exists(self.template_directory):
                os.makedirs(self.template_directory)
                self._create_default_templates()
            
            self.jinja_env = Environment(
                loader=FileSystemLoader(self.template_directory),
                autoescape=True
            )
            
            logger.info("‚úÖ Template engine initialized")
            
        except Exception as e:
            logger.error(f"‚ùå Template initialization failed: {e}")
            raise
    
    def _initialize_database(self):
        """Initialize database connection"""
        try:
            self.db_connection = psycopg2.connect(
                self.config.get('database_url', 'postgresql://localhost/velocity_agents'),
                cursor_factory=psycopg2.extras.RealDictCursor
            )
            self.db_connection.autocommit = True
            logger.info("‚úÖ Database connection established")
            
        except Exception as e:
            logger.error(f"‚ùå Database connection failed: {e}")
            raise
    
    def _setup_output_directory(self):
        """Setup output directory structure"""
        try:
            os.makedirs(self.output_directory, exist_ok=True)
            
            # Create subdirectories for different document types
            subdirs = ['reports', 'assessments', 'policies', 'procedures', 'temp']
            for subdir in subdirs:
                os.makedirs(os.path.join(self.output_directory, subdir), exist_ok=True)
            
            logger.info("‚úÖ Output directory structure created")
            
        except Exception as e:
            logger.error(f"‚ùå Output directory setup failed: {e}")
            raise
    
    def _create_default_templates(self):
        """Create default document templates"""
        templates = {
            'soc2_report.html': """
<!DOCTYPE html>
<html>
<head>
    <title>SOC 2 Type II Report - {{ organization_name }}</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 2em; }
        .header { border-bottom: 3px solid #6366f1; padding-bottom: 1em; }
        .section { margin: 2em 0; }
        .evidence-table { width: 100%; border-collapse: collapse; }
        .evidence-table th, .evidence-table td { border: 1px solid #ddd; padding: 8px; }
        .evidence-table th { background-color: #f2f2f2; }
        .compliance-status { padding: 4px 8px; border-radius: 4px; }
        .compliant { background-color: #dcfce7; color: #166534; }
        .non-compliant { background-color: #fecaca; color: #991b1b; }
    </style>
</head>
<body>
    <div class="header">
        <h1>SOC 2 Type II Report</h1>
        <h2>{{ organization_name }}</h2>
        <p>Report Period: {{ start_date }} to {{ end_date }}</p>
        <p>Generated: {{ generation_date }}</p>
    </div>
    
    <div class="section">
        <h2>Executive Summary</h2>
        <p>{{ executive_summary }}</p>
    </div>
    
    <div class="section">
        <h2>Trust Service Criteria</h2>
        {% for criterion in trust_criteria %}
        <h3>{{ criterion.name }}</h3>
        <p>{{ criterion.description }}</p>
        <p><strong>Status:</strong> 
            <span class="compliance-status {{ criterion.status }}">{{ criterion.status|title }}</span>
        </p>
        {% endfor %}
    </div>
    
    <div class="section">
        <h2>Evidence Summary</h2>
        <table class="evidence-table">
            <thead>
                <tr>
                    <th>Control</th>
                    <th>Evidence Type</th>
                    <th>Collection Date</th>
                    <th>Status</th>
                </tr>
            </thead>
            <tbody>
                {% for evidence in evidence_items %}
                <tr>
                    <td>{{ evidence.control }}</td>
                    <td>{{ evidence.type }}</td>
                    <td>{{ evidence.collection_date }}</td>
                    <td><span class="compliance-status {{ evidence.status }}">{{ evidence.status|title }}</span></td>
                </tr>
                {% endfor %}
            </tbody>
        </table>
    </div>
</body>
</html>
""",
            'iso27001_report.html': """
<!DOCTYPE html>
<html>
<head>
    <title>ISO 27001 Compliance Report - {{ organization_name }}</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 2em; }
        .header { border-bottom: 3px solid #059669; padding-bottom: 1em; }
        .section { margin: 2em 0; }
        .control-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(300px, 1fr)); gap: 1em; }
        .control-card { border: 1px solid #ddd; padding: 1em; border-radius: 8px; }
    </style>
</head>
<body>
    <div class="header">
        <h1>ISO 27001 Compliance Report</h1>
        <h2>{{ organization_name }}</h2>
        <p>Assessment Date: {{ assessment_date }}</p>
        <p>Generated: {{ generation_date }}</p>
    </div>
    
    <div class="section">
        <h2>Information Security Management System</h2>
        <p>{{ isms_summary }}</p>
    </div>
    
    <div class="section">
        <h2>Control Assessment Results</h2>
        <div class="control-grid">
            {% for control in controls %}
            <div class="control-card">
                <h4>{{ control.id }}: {{ control.name }}</h4>
                <p>{{ control.description }}</p>
                <p><strong>Implementation:</strong> {{ control.implementation_status }}</p>
                <p><strong>Effectiveness:</strong> {{ control.effectiveness }}</p>
            </div>
            {% endfor %}
        </div>
    </div>
</body>
</html>
""",
            'gdpr_assessment.html': """
<!DOCTYPE html>
<html>
<head>
    <title>GDPR Compliance Assessment - {{ organization_name }}</title>
    <style>
        body { font-family: Arial, sans-serif; margin: 2em; }
        .header { border-bottom: 3px solid #dc2626; padding-bottom: 1em; }
        .section { margin: 2em 0; }
        .privacy-grid { display: grid; grid-template-columns: repeat(auto-fit, minmax(350px, 1fr)); gap: 1em; }
        .privacy-card { border: 1px solid #ddd; padding: 1em; border-radius: 8px; }
    </style>
</head>
<body>
    <div class="header">
        <h1>GDPR Compliance Assessment</h1>
        <h2>{{ organization_name }}</h2>
        <p>Assessment Period: {{ assessment_period }}</p>
        <p>Generated: {{ generation_date }}</p>
    </div>
    
    <div class="section">
        <h2>Data Protection Impact Assessment</h2>
        <p>{{ dpia_summary }}</p>
    </div>
    
    <div class="section">
        <h2>Privacy Principles Compliance</h2>
        <div class="privacy-grid">
            {% for principle in privacy_principles %}
            <div class="privacy-card">
                <h4>{{ principle.name }}</h4>
                <p>{{ principle.description }}</p>
                <p><strong>Compliance Level:</strong> {{ principle.compliance_level }}</p>
                {% if principle.recommendations %}
                <p><strong>Recommendations:</strong> {{ principle.recommendations }}</p>
                {% endif %}
            </div>
            {% endfor %}
        </div>
    </div>
</body>
</html>
"""
        }
        
        for template_name, content in templates.items():
            template_path = os.path.join(self.template_directory, template_name)
            with open(template_path, 'w') as f:
                f.write(content)
        
        logger.info(f"‚úÖ Created {len(templates)} default templates")
    
    async def start_processing(self):
        """Start the document generation processing loop"""
        logger.info("üîç Starting document generation processing")
        
        try:
            while True:
                processing_start = datetime.utcnow()
                
                # Check for new requests
                await self._check_new_requests()
                
                # Process pending requests
                await self._process_requests()
                
                # Update metrics
                self.metrics['last_generation_time'] = processing_start.isoformat()
                
                processing_duration = (datetime.utcnow() - processing_start).total_seconds()
                logger.info(f"‚úÖ Processing cycle completed in {processing_duration:.2f}s")
                
                # Send heartbeat with metrics
                await self._send_heartbeat()
                
                # Wait for next processing interval
                await asyncio.sleep(self.config.get('processing_interval', 60))  # 1 minute default
                
        except Exception as e:
            logger.error(f"‚ùå Document processing error: {e}")
            await asyncio.sleep(30)  # Wait before retry
    
    async def _check_new_requests(self):
        """Check for new document generation requests"""
        try:
            with self.db_connection.cursor() as cursor:
                cursor.execute("""
                    SELECT * FROM document_requests 
                    WHERE status = 'pending' AND agent_id = %s
                    ORDER BY created_at ASC
                """, (self.agent_id,))
                
                requests = cursor.fetchall()
                
                for request_data in requests:
                    request = DocumentRequest(
                        request_id=request_data['id'],
                        document_type=request_data['document_type'],
                        framework=request_data['framework'],
                        output_format=request_data['output_format'],
                        template_id=request_data['template_id'],
                        evidence_filters=json.loads(request_data['evidence_filters']),
                        customizations=json.loads(request_data['customizations']),
                        requester_id=request_data['requester_id'],
                        due_date=request_data['due_date'],
                        status='pending'
                    )
                    
                    self.request_queue.append(request)
                    
                    # Update request status to processing
                    cursor.execute("""
                        UPDATE document_requests 
                        SET status = 'processing', updated_at = NOW()
                        WHERE id = %s
                    """, (request.request_id,))
                
                if requests:
                    logger.info(f"üìã Added {len(requests)} new document requests to queue")
                    
        except Exception as e:
            logger.error(f"‚ùå Failed to check new requests: {e}")
    
    async def _process_requests(self):
        """Process document generation requests"""
        if not self.request_queue:
            return
        
        # Move requests to processing queue
        self.processing_queue.extend(self.request_queue)
        self.request_queue.clear()
        
        for request in self.processing_queue:
            try:
                logger.info(f"üìÑ Processing document request {request.request_id}")
                
                generation_start = datetime.utcnow()
                
                # Generate the document
                document = await self._generate_document(request)
                
                generation_time = (datetime.utcnow() - generation_start).total_seconds()
                document.generation_time = generation_time
                
                # Store document metadata
                await self._store_document_metadata(document)
                
                # Update request status
                await self._update_request_status(request.request_id, 'completed')
                
                # Update metrics
                self.metrics['documents_generated'] += 1
                self.metrics['requests_completed'] += 1
                self.metrics['generation_time_total'] += generation_time
                self.metrics['total_pages_created'] += document.page_count
                
                self.completed_documents.append(document)
                
                logger.info(f"‚úÖ Document {document.document_id} generated successfully")
                
            except Exception as e:
                logger.error(f"‚ùå Failed to generate document for request {request.request_id}: {e}")
                await self._update_request_status(request.request_id, 'failed')
                self.metrics['requests_failed'] += 1
        
        # Clear processing queue
        self.processing_queue.clear()
    
    async def _generate_document(self, request: DocumentRequest) -> GeneratedDocument:
        """Generate a document based on the request"""
        # Gather evidence data
        evidence_data = await self._gather_evidence(request.evidence_filters)
        
        # Generate AI content if available
        ai_content = await self._generate_ai_content(request, evidence_data)
        
        # Prepare template context
        context = await self._prepare_template_context(request, evidence_data, ai_content)
        
        # Render document
        output_path = await self._render_document(request, context)
        
        # Calculate document metadata
        file_size = os.path.getsize(output_path)
        page_count = await self._estimate_page_count(output_path, request.output_format)
        
        # Generate document hash
        with open(output_path, 'rb') as f:
            file_hash = hashlib.sha256(f.read()).hexdigest()
        
        document_id = f"{request.framework}_{request.document_type}_{datetime.utcnow().timestamp()}"
        
        return GeneratedDocument(
            document_id=document_id,
            request_id=request.request_id,
            document_type=request.document_type,
            framework=request.framework,
            output_format=request.output_format,
            file_path=output_path,
            file_size=file_size,
            page_count=page_count,
            evidence_count=len(evidence_data),
            generation_time=0.0,  # Will be set by caller
            status='completed',
            created_at=datetime.utcnow().isoformat(),
            hash=file_hash
        )
    
    async def _gather_evidence(self, filters: Dict[str, Any]) -> List[Dict]:
        """Gather evidence data based on filters"""
        try:
            with self.db_connection.cursor() as cursor:
                # Build dynamic query based on filters
                where_conditions = []
                params = []
                
                if filters.get('source_system'):
                    where_conditions.append("source_system = %s")
                    params.append(filters['source_system'])
                
                if filters.get('evidence_type'):
                    where_conditions.append("evidence_type = %s")
                    params.append(filters['evidence_type'])
                
                if filters.get('compliance_framework'):
                    where_conditions.append("compliance_framework LIKE %s")
                    params.append(f"%{filters['compliance_framework']}%")
                
                if filters.get('date_range'):
                    start_date = filters['date_range'].get('start')
                    end_date = filters['date_range'].get('end')
                    if start_date and end_date:
                        where_conditions.append("collection_timestamp BETWEEN %s AND %s")
                        params.extend([start_date, end_date])
                
                where_clause = " AND ".join(where_conditions) if where_conditions else "1=1"
                
                query = f"""
                    SELECT * FROM evidence_collection 
                    WHERE {where_clause}
                    ORDER BY collection_timestamp DESC
                    LIMIT 1000
                """
                
                cursor.execute(query, params)
                evidence_records = cursor.fetchall()
                
                logger.info(f"üìä Gathered {len(evidence_records)} evidence items")
                self.metrics['evidence_items_processed'] += len(evidence_records)
                
                return [dict(record) for record in evidence_records]
                
        except Exception as e:
            logger.error(f"‚ùå Failed to gather evidence: {e}")
            return []
    
    async def _generate_ai_content(self, request: DocumentRequest, evidence_data: List[Dict]) -> Dict[str, Any]:
        """Generate AI-powered content for the document"""
        if not self.llm:
            return {
                'executive_summary': 'Executive summary generation requires AI configuration.',
                'recommendations': 'AI-powered recommendations not available.',
                'risk_assessment': 'Risk assessment requires AI configuration.'
            }
        
        try:
            # Create evidence context for AI
            evidence_context = self._prepare_evidence_context(evidence_data)
            
            # Generate executive summary
            summary_prompt = PromptTemplate(
                input_variables=["framework", "evidence_context", "organization"],
                template="""
                You are a compliance expert generating an executive summary for a {framework} compliance report.
                
                Based on the following evidence data:
                {evidence_context}
                
                Generate a professional executive summary for {organization} that:
                1. Summarizes the overall compliance posture
                2. Highlights key findings and achievements
                3. Identifies areas for improvement
                4. Uses appropriate technical language for executives
                
                Executive Summary:
                """
            )
            
            summary_chain = LLMChain(llm=self.llm, prompt=summary_prompt)
            
            executive_summary = summary_chain.run(
                framework=request.framework,
                evidence_context=evidence_context,
                organization=request.customizations.get('organization_name', 'Organization')
            )
            
            # Generate recommendations
            recommendations_prompt = PromptTemplate(
                input_variables=["framework", "evidence_context"],
                template="""
                Based on the compliance evidence for {framework}:
                {evidence_context}
                
                Provide 3-5 specific, actionable recommendations to improve compliance posture:
                """
            )
            
            recommendations_chain = LLMChain(llm=self.llm, prompt=recommendations_prompt)
            
            recommendations = recommendations_chain.run(
                framework=request.framework,
                evidence_context=evidence_context
            )
            
            return {
                'executive_summary': executive_summary.strip(),
                'recommendations': recommendations.strip(),
                'risk_assessment': 'AI-generated risk assessment based on evidence analysis'
            }
            
        except Exception as e:
            logger.error(f"‚ùå AI content generation failed: {e}")
            return {
                'executive_summary': 'Executive summary generation encountered an error.',
                'recommendations': 'Recommendation generation not available.',
                'risk_assessment': 'Risk assessment generation failed.'
            }
    
    def _prepare_evidence_context(self, evidence_data: List[Dict]) -> str:
        """Prepare evidence data as context for AI processing"""
        if not evidence_data:
            return "No evidence data available."
        
        # Summarize evidence by type and compliance status
        evidence_summary = {}
        for evidence in evidence_data[:50]:  # Limit to first 50 for context size
            evidence_type = evidence.get('evidence_type', 'unknown')
            status = evidence.get('verification_status', 'unknown')
            
            if evidence_type not in evidence_summary:
                evidence_summary[evidence_type] = {'compliant': 0, 'non_compliant': 0, 'total': 0}
            
            evidence_summary[evidence_type]['total'] += 1
            if status == 'compliant':
                evidence_summary[evidence_type]['compliant'] += 1
            else:
                evidence_summary[evidence_type]['non_compliant'] += 1
        
        context_parts = []
        for evidence_type, counts in evidence_summary.items():
            compliance_rate = (counts['compliant'] / counts['total']) * 100 if counts['total'] > 0 else 0
            context_parts.append(f"{evidence_type}: {counts['total']} items, {compliance_rate:.1f}% compliant")
        
        return "\n".join(context_parts)
    
    async def _prepare_template_context(self, request: DocumentRequest, evidence_data: List[Dict], ai_content: Dict) -> Dict[str, Any]:
        """Prepare context data for template rendering"""
        
        # Base context
        context = {
            'organization_name': request.customizations.get('organization_name', 'Organization'),
            'generation_date': datetime.utcnow().strftime('%B %d, %Y'),
            'report_period': request.customizations.get('report_period', 'Current Year'),
            'framework': request.framework,
            'document_type': request.document_type,
            'evidence_items': evidence_data[:100],  # Limit for template processing
            'total_evidence_count': len(evidence_data),
            **ai_content
        }
        
        # Framework-specific context
        if request.framework.upper() == 'SOC2':
            context.update(self._prepare_soc2_context(evidence_data))
        elif request.framework.upper() == 'ISO27001':
            context.update(self._prepare_iso27001_context(evidence_data))
        elif request.framework.upper() == 'GDPR':
            context.update(self._prepare_gdpr_context(evidence_data))
        
        return context
    
    def _prepare_soc2_context(self, evidence_data: List[Dict]) -> Dict[str, Any]:
        """Prepare SOC 2 specific context"""
        trust_criteria = [
            {
                'name': 'Security',
                'description': 'Protection against unauthorized access',
                'status': 'compliant',
                'evidence_count': len([e for e in evidence_data if 'security' in e.get('evidence_type', '').lower()])
            },
            {
                'name': 'Availability',
                'description': 'System operational availability',
                'status': 'compliant',
                'evidence_count': len([e for e in evidence_data if 'availability' in e.get('evidence_type', '').lower()])
            },
            {
                'name': 'Processing Integrity',
                'description': 'System processing completeness and accuracy',
                'status': 'partial',
                'evidence_count': len([e for e in evidence_data if 'integrity' in e.get('evidence_type', '').lower()])
            },
            {
                'name': 'Confidentiality',
                'description': 'Protection of confidential information',
                'status': 'compliant',
                'evidence_count': len([e for e in evidence_data if 'confidentiality' in e.get('evidence_type', '').lower()])
            },
            {
                'name': 'Privacy',
                'description': 'Collection, use, retention, and disposal of personal information',
                'status': 'compliant',
                'evidence_count': len([e for e in evidence_data if 'privacy' in e.get('evidence_type', '').lower()])
            }
        ]
        
        return {
            'trust_criteria': trust_criteria,
            'start_date': (datetime.utcnow() - timedelta(days=365)).strftime('%B %d, %Y'),
            'end_date': datetime.utcnow().strftime('%B %d, %Y')
        }
    
    def _prepare_iso27001_context(self, evidence_data: List[Dict]) -> Dict[str, Any]:
        """Prepare ISO 27001 specific context"""
        controls = [
            {
                'id': 'A.5',
                'name': 'Information Security Policies',
                'description': 'Management direction and support for information security',
                'implementation_status': 'Implemented',
                'effectiveness': 'Effective'
            },
            {
                'id': 'A.6',
                'name': 'Organization of Information Security',
                'description': 'Organization of information security',
                'implementation_status': 'Implemented',
                'effectiveness': 'Effective'
            },
            {
                'id': 'A.8',
                'name': 'Asset Management',
                'description': 'Asset management controls',
                'implementation_status': 'Partially Implemented',
                'effectiveness': 'Needs Improvement'
            }
        ]
        
        return {
            'controls': controls,
            'assessment_date': datetime.utcnow().strftime('%B %d, %Y'),
            'isms_summary': 'Information Security Management System assessment summary'
        }
    
    def _prepare_gdpr_context(self, evidence_data: List[Dict]) -> Dict[str, Any]:
        """Prepare GDPR specific context"""
        privacy_principles = [
            {
                'name': 'Lawfulness, Fairness and Transparency',
                'description': 'Processing must be lawful, fair and transparent',
                'compliance_level': 'Compliant',
                'recommendations': None
            },
            {
                'name': 'Purpose Limitation',
                'description': 'Data collected for specified, explicit and legitimate purposes',
                'compliance_level': 'Compliant',
                'recommendations': None
            },
            {
                'name': 'Data Minimization',
                'description': 'Data should be adequate, relevant and limited',
                'compliance_level': 'Needs Improvement',
                'recommendations': 'Review data collection practices to ensure minimization'
            },
            {
                'name': 'Accuracy',
                'description': 'Personal data should be accurate and kept up to date',
                'compliance_level': 'Compliant',
                'recommendations': None
            }
        ]
        
        return {
            'privacy_principles': privacy_principles,
            'assessment_period': f"January 1, {datetime.utcnow().year} - {datetime.utcnow().strftime('%B %d, %Y')}",
            'dpia_summary': 'Data Protection Impact Assessment summary'
        }
    
    async def _render_document(self, request: DocumentRequest, context: Dict[str, Any]) -> str:
        """Render the document using templates"""
        try:
            # Determine template file
            template_name = f"{request.framework.lower()}_{request.document_type.lower()}.html"
            
            if template_name not in [template.name for template in self.jinja_env.list_templates()]:
                template_name = 'soc2_report.html'  # Fallback template
            
            # Render HTML template
            template = self.jinja_env.get_template(template_name)
            html_content = template.render(**context)
            
            # Generate output filename
            timestamp = datetime.utcnow().strftime('%Y%m%d_%H%M%S')
            base_filename = f"{request.framework}_{request.document_type}_{timestamp}"
            
            # Convert to requested format
            if request.output_format.lower() == 'pdf':
                output_path = os.path.join(self.output_directory, 'reports', f"{base_filename}.pdf")
                HTML(string=html_content).write_pdf(output_path)
            
            elif request.output_format.lower() == 'html':
                output_path = os.path.join(self.output_directory, 'reports', f"{base_filename}.html")
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(html_content)
            
            elif request.output_format.lower() == 'docx':
                output_path = os.path.join(self.output_directory, 'reports', f"{base_filename}.docx")
                await self._convert_to_docx(html_content, output_path, context)
            
            else:
                # Default to HTML
                output_path = os.path.join(self.output_directory, 'reports', f"{base_filename}.html")
                with open(output_path, 'w', encoding='utf-8') as f:
                    f.write(html_content)
            
            logger.info(f"üìÑ Document rendered to {output_path}")
            return output_path
            
        except Exception as e:
            logger.error(f"‚ùå Document rendering failed: {e}")
            raise
    
    async def _convert_to_docx(self, html_content: str, output_path: str, context: Dict[str, Any]):
        """Convert HTML content to DOCX format"""
        try:
            doc = DocxDocument()
            
            # Add title
            title = doc.add_heading(f"{context['framework']} {context['document_type']}", 0)
            
            # Add organization name
            doc.add_heading(context['organization_name'], level=1)
            
            # Add generation date
            doc.add_paragraph(f"Generated: {context['generation_date']}")
            
            # Add executive summary
            if 'executive_summary' in context:
                doc.add_heading('Executive Summary', level=2)
                doc.add_paragraph(context['executive_summary'])
            
            # Add evidence summary
            doc.add_heading('Evidence Summary', level=2)
            doc.add_paragraph(f"Total evidence items processed: {context['total_evidence_count']}")
            
            # Save document
            doc.save(output_path)
            
        except Exception as e:
            logger.error(f"‚ùå DOCX conversion failed: {e}")
            # Fallback to HTML
            html_path = output_path.replace('.docx', '.html')
            with open(html_path, 'w', encoding='utf-8') as f:
                f.write(html_content)
            return html_path
    
    async def _estimate_page_count(self, file_path: str, format: str) -> int:
        """Estimate page count for the generated document"""
        try:
            if format.lower() == 'pdf':
                # For PDF, could use PyPDF2 or similar to get actual page count
                # For now, estimate based on file size
                file_size = os.path.getsize(file_path)
                estimated_pages = max(1, file_size // 50000)  # Rough estimate
                return estimated_pages
            
            elif format.lower() in ['html', 'docx']:
                # Estimate based on content length
                with open(file_path, 'r', encoding='utf-8') as f:
                    content = f.read()
                    # Rough estimate: 3000 characters per page
                    estimated_pages = max(1, len(content) // 3000)
                    return estimated_pages
            
            return 1
            
        except Exception as e:
            logger.error(f"‚ùå Page count estimation failed: {e}")
            return 1
    
    async def _store_document_metadata(self, document: GeneratedDocument):
        """Store document metadata in database"""
        try:
            with self.db_connection.cursor() as cursor:
                cursor.execute("""
                    INSERT INTO generated_documents 
                    (id, request_id, document_type, framework, output_format, 
                     file_path, file_size, page_count, evidence_count, 
                     generation_time, status, created_at, hash, agent_id)
                    VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s, %s)
                """, (
                    document.document_id,
                    document.request_id,
                    document.document_type,
                    document.framework,
                    document.output_format,
                    document.file_path,
                    document.file_size,
                    document.page_count,
                    document.evidence_count,
                    document.generation_time,
                    document.status,
                    document.created_at,
                    document.hash,
                    self.agent_id
                ))
            
        except Exception as e:
            logger.error(f"‚ùå Failed to store document metadata: {e}")
    
    async def _update_request_status(self, request_id: str, status: str):
        """Update document request status"""
        try:
            with self.db_connection.cursor() as cursor:
                cursor.execute("""
                    UPDATE document_requests 
                    SET status = %s, updated_at = NOW()
                    WHERE id = %s
                """, (status, request_id))
                
        except Exception as e:
            logger.error(f"‚ùå Failed to update request status: {e}")
    
    async def _send_heartbeat(self):
        """Send heartbeat with metrics to orchestrator"""
        try:
            avg_generation_time = (
                self.metrics['generation_time_total'] / self.metrics['documents_generated']
                if self.metrics['documents_generated'] > 0 else 0
            )
            
            heartbeat_data = {
                'type': 'heartbeat',
                'agent_id': self.agent_id,
                'timestamp': datetime.utcnow().isoformat(),
                'metrics': {
                    'cpu_usage': 25.0,  # Would get actual CPU usage
                    'memory_usage_mb': 256,  # Would get actual memory usage
                    'response_time_ms': 300,  # Would calculate actual response time
                    'documents_generated': self.metrics['documents_generated'],
                    'total_pages_created': self.metrics['total_pages_created'],
                    'evidence_items_processed': self.metrics['evidence_items_processed'],
                    'requests_completed': self.metrics['requests_completed'],
                    'requests_failed': self.metrics['requests_failed'],
                    'avg_generation_time': avg_generation_time,
                    'queue_size': len(self.request_queue) + len(self.processing_queue)
                }
            }
            
            print(json.dumps(heartbeat_data))  # Send to orchestrator via stdout
            
        except Exception as e:
            logger.error(f"‚ùå Failed to send heartbeat: {e}")
    
    async def get_health_status(self) -> Dict[str, Any]:
        """Get agent health status for monitoring"""
        return {
            'agent_id': self.agent_id,
            'status': 'healthy',
            'metrics': self.metrics,
            'queue_sizes': {
                'request_queue': len(self.request_queue),
                'processing_queue': len(self.processing_queue),
                'completed_documents': len(self.completed_documents)
            },
            'database_connected': self.db_connection is not None,
            'ai_available': self.llm is not None,
            'templates_loaded': len(self.jinja_env.list_templates()) if self.jinja_env else 0,
            'output_directory': self.output_directory,
            'last_heartbeat': datetime.utcnow().isoformat()
        }
    
    async def shutdown(self):
        """Graceful shutdown of the agent"""
        logger.info(f"üõë Shutting down Document Generator {self.agent_id}")
        
        # Complete any pending requests
        if self.processing_queue:
            logger.info(f"‚è≥ Completing {len(self.processing_queue)} pending requests")
            await self._process_requests()
        
        # Close database connection
        if self.db_connection:
            self.db_connection.close()
        
        logger.info("‚úÖ Document Generator shutdown complete")

# Main execution for standalone testing
async def main():
    """Main function for testing the Document Generator"""
    
    # Test configuration
    config = {
        'agent_id': 'document-generator-test',
        'openai_api_key': 'test_key',  # Would use real OpenAI key
        'output_directory': './test_documents',
        'template_directory': './test_templates',
        'processing_interval': 30,
        'database_url': 'postgresql://localhost/velocity_agents'
    }
    
    try:
        # Create and start generator
        generator = DocumentGenerator(config)
        
        # Run health check
        health = await generator.get_health_status()
        print(f"Agent Health: {json.dumps(health, indent=2)}")
        
        # Start processing (would run indefinitely in production)
        # await generator.start_processing()
        
    except Exception as e:
        logger.error(f"‚ùå Agent startup failed: {e}")

if __name__ == "__main__":
    asyncio.run(main())